\documentclass[11pt]{article}

% Page layout (single-column, professional margins)
\usepackage[margin=1in]{geometry}

% Fonts and text
\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}

% Figures and tables
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}

% Math
\usepackage{amsmath}

% URLs
\usepackage{url}
\usepackage{float}

% Title
\title{Group 3 Final Report:\\Heart Disease Prediction using Machine Learning}

\author{
ZhiChong Lin, ZiDi Yao, Ke Ma\\
\texttt{yaoz25@mcmaster.ca, mak11@mcmaster.ca, lin281@mcmaster.ca}
}

\date{}
\setlength{\parindent}{2em} 

\begin{document}
\maketitle

% ============================================================
\section{Introduction}

    This project aims to use ML method to predict the likelihood
of heart disease based on eleven clinical and demographic features. Heart
disease continues to be a major global health concern, and early detection is
crucial for reducing severe outcomes. As outlined in our project proposal, the
goal of this work is to develop a reliable classification model that can
identify high-risk patients using routinely collected medical measurements.

    Building on prior studies, our project uses a supervised learning
pipeline based on Principal Component Analysis (PCA) and an RBF-kernel SVM
classifier. We preprocess the data with a column transformer that standardizes
numerical features and applies one-hot encoding to categorical features, then
apply PCA and keep the number of components according to the Kaiser
criterion~\cite{kaiser1960factor}. The resulting low-dimensional
representations are fed into an RBF-SVM, and the full pipeline is evaluated on
the Kaggle Heart Failure Prediction dataset~\cite{heartfailure_kaggle} using
stratified 5-fold cross validation with standard metrics (accuracy, precision, recall, F1-score, and ROC–AUC).

% ============================================================
\section{Related Work}

Our project builds directly on the foundation built in
Process Report and TA's Feedback, where we considered both the clinical motivation and the technical
approaches. In that proposal, we discussed the limitations of traditional diagnostic methods and highlighted the
importance of ML models that can identify  multi-feature interactions such as age, cholesterol level, chest pain type, and 
ECG-related measurements, which observations align with prior work showing that 
heart disease prediction is well suited to ML due to its 
multivariate and non-linear nature.

As we talked about in M1, several existing studies have explored this predictive task using classical and
modern machine learning techniques. Logistic regression remains a common 
baseline method, as demonstrated by Awan \cite{musmanaslamawan_heartdisease_logistic},
who achieved approximately 85\% accuracy on the Kaggle using minimal
feature engineering. More advanced pipelines integrate supervised feature 
selection and dimensionality reduction. The Chi-Square + PCA framework proposed 
by Gárate-Escamila et al. \cite{GARATEESCAMILA2020100330} achieved up to 99\%
accuracy on multiple UCI heart disease datasets, motivating our decision in
Milestone~1 to incorporate both Chi-Square filtering and PCA into our own
preprocessing pipeline.

Moreover, foundational statistic work such as Kaiser factor analysis criterion
\cite{kaiser1960factor} provides justification for retaining only
principal components with eigenvalues greater than one, a rule we apply in our
dimensionality reduction stage. Other work has examined optimization strategies 
for medical classification models, including scalable L1-regularized training
\cite{andrew2007scalable} and multi-task predictive structure learning
\cite{Ando2005}, which highlight broader approaches to improving generalization
when datasets are small—one of the challenges noted in our proposal.

\section{Dataset and Preprocessing} 

This section will introduce the raw dataset we used, and how we clean and process it. 

\subsection{Dataset Description}

The dataset we used in this project is the \textit{Heart Failure Prediction Dataset}
published by Fedesoriano on Kaggle~\cite{heartfailure_kaggle}.  
It contains \textbf{918 patient observations} and \textbf{12 attributes}, including 
11 clinical predictor variables and one binary target label indicating the presence 
of heart disease. This dataset was designed to support research on early detection 
of cardiovascular risks, particularly heart failure, which remains one of the leading 
causes of global mortality.

The dataset includes a mixture of demographic features ( Age, Sex), 
physiological measurements (like RestingBP, Cholesterol, MaxHR), and exercise-induced 
ECG-related metrics (ExerciseAngina, Oldpeak, ST\_Slope). Those attributes show 
common risk factors used in medical diagnostics for cardiovascular disease and have 
been widely adopted in machine learning models for clinical prediction tasks.

A complete list of raw features and their corresponding descriptions is provided in 
Table~\ref{tab:rawfeatures}.


\begin{table}[htbp]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Feature} & \textbf{Description} \\
\midrule
Age & Age of patient (years) \\
Sex & Biological sex (M/F) \\
ChestPainType & Chest pain type (ATA, NAP, ASY, TA) \\
RestingBP & Resting blood pressure (mm Hg) \\
Cholesterol & Serum cholesterol (mg/dL) \\
FastingBS & Fasting blood sugar (0/1) \\
RestingECG & Resting ECG results (Normal, ST, LVH) \\
MaxHR & Maximum heart rate achieved \\
ExerciseAngina & Exercise-induced angina (Y/N) \\
Oldpeak & ST depression value induced by exercise \\
ST\_Slope & Slope of ST segment (Up, Flat, Down) \\
HeartDisease & Target label (1 = disease, 0 = healthy) \\
\bottomrule
\end{tabular}
\caption{Raw dataset features.}
\label{tab:rawfeatures}
\end{table}

Originally, the dataset contains:
\[
\textbf{918 samples} \quad \times \quad \textbf{11 features}.
\]
\subsection{Feature Preprocessing}

The feature matrix \(X\) was constructed by removing the target column and
retaining the remaining 18 input attributes.
Since the dataset includes both numerical and categorical variables, several
preprocessing steps were required to convert all values into a machine-learning‐
ready numeric form.

\paragraph{Binary Encoding}

Three features, namely Sex, ExerciseAngina, and FastingBS contain only two possible values and were mapped directly to
0/1 following our preprocessing script:

\begin{itemize}
    \item \textbf{Sex:} \texttt{M} $\rightarrow$ 1,\; \texttt{F} $\rightarrow$ 0
    \item \textbf{ExerciseAngina:} \texttt{Y} $\rightarrow$ 1,\; \texttt{N} $\rightarrow$ 0
    \item \textbf{FastingBS:} preserved as integer \texttt{0/1}
\end{itemize}

\paragraph{Ordinal Mapping of Multi-Class Features}

Three categorical features contain more than two categories.
In the stored processed dataset (\texttt{X\_encoded.csv}), they were converted
to integer codes according to predefined mappings:

\[
\text{ChestPainType: } \{\texttt{ATA}, \texttt{NAP}, \texttt{ASY}, \texttt{TA}\}
\rightarrow \{0,1,2,3\},
\]

\[
\text{RestingECG: } \{\texttt{Normal}, \texttt{ST}, \texttt{LVH}\}
\rightarrow \{0,1,2\},
\]

\[
\text{ST\_Slope: } \{\texttt{Up}, \texttt{Flat}, \texttt{Down}\}
\rightarrow \{0,1,2\}.
\]

These mappings avoid string-based ambiguity and ensure that all feature columns are numeric at the preprocessing stage.

In contrast from progress report, we adopted feedback from TA to change our way of presenting One-Hot Encoding, instead of present them in one single column to split them across the columns 
for every single category.

Therefore, after spliting them into one-hot encoding, the final dataset shape changes to 918 x 18.

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Feature} & \textbf{Description} \\
\midrule
Age & Age of patient (years) \\
Sex & Biological sex (M/F) \\
ChestPainType\_0 & ATA \\
ChestPainType\_1 & NAP \\
ChestPainType\_2 & ASY \\
ChestPainType\_3 & TA \\
RestingBP & Resting blood pressure (mm Hg) \\
Cholesterol & Serum cholesterol (mg/dL) \\
FastingBS & Fasting blood sugar (0/1) \\
RestingECG\_0 & Normal \\
RestingECG\_1 & ST \\
RestingECG\_2 & LVH \\
MaxHR & Maximum heart rate achieved \\
ExerciseAngina & Exercise-induced angina (Y/N) \\
Oldpeak & ST depression value induced by exercise \\
ST\_Slope\_0 & Up \\
ST\_Slope\_1 & Flat \\
ST\_Slope\_2 & Down \\
HeartDisease & Target label (1 = disease, 0 = healthy) \\
\bottomrule
\end{tabular}
\caption{One-Hot Encoding Table.}
\label{tab:rawfeatures}
\end{table}


\subsection{Target Label Extraction}

The target label \texttt{HeartDisease} is a binary indicator representing whether
a patient shows signs of heart disease.  
We extract this column and converted it to integer form using:
\[
y = \texttt{df['HeartDisease'].astype(int)}.
\]
The resulting is a one-dimensional vector , which was saved as \texttt{processed/y.csv}
for all downstream training and evaluation.

The cleaned dataset was saved to \texttt{processed/X\_encoded.csv}, and
the corresponding feature names were exported to
\texttt{processed/feature\_names.txt} for reproducibility.


% ============================================================

% This section corresponds to Item 3 in the project instructions.
\section{Model Inputs (Features)}

During our data preprocessing phase, we use \texttt{scikit-learn} 
\texttt{Pipeline} and \texttt{ColumnTransformer} to transform the raw
attributes before training. Numerical features (Age, RestingBP, Cholesterol,
MaxHR, Oldpeak, FastingBS) are imputed with the median and standardized, while
categorical features (Sex, ChestPainType, RestingECG, ExerciseAngina, ST\_Slope)
are converted into one-hot vectors. After this step each patient is represented
by an 18-dimensional feature vector, matching the one-hot layout described in
Table~\ref{tab:rawfeatures}.

Motivated by our progress report and TA feedback, in the final system we use
PCA as our only feature-engineering method, instead of the Chi-square + PCA
combination proposed in~\cite{GARATEESCAMILA2020100330}.

\begin{itemize}
    \item \textbf{PCA.}
    We apply Principal Component Analysis (PCA) to the standardized and
    one-hot encoded features to reduce dimensionality. PCA finds orthogonal
    directions (principal components) that capture the largest variance in the
    data and projects each sample onto these directions. To choose the number
    of components we adopt the Kaiser criterion~\cite{kaiser1960factor},
    keeping only components with eigenvalues greater than 1. In our
    experiments the first five components satisfy this rule, so we retain
    five principal components for the final representation.
\end{itemize}

Hence, each patient sample is represented as a compact 5-dimensional feature
vector summarizing the most informative physiological and categorical
characteristics, which is then used as input to our machine learning models.


\section{Model Implementation}

We have implemented a supervised learning pipeline for binary classification of heart disease presence. 
Our main model is a \textbf{Support Vector Machine (SVM)} with a \textbf{Radial Basis Function (RBF)} kernel, implemented using the \texttt{scikit-learn} library. 
This kernel choice allows the decision boundary to be nonlinear, which is important given the heterogeneous mixture of categorical and numerical medical features in the dataset. 

\textbf{Loss Function:}
\[
\min_{\mathbf{w},b} \frac{1}{2}\|\mathbf{w}\|^2 + C \sum_{i=1}^n \max(0, 1 - y_i(\mathbf{w}^\top \phi(\mathbf{x}_i) + b))
\]
where $C$ is the penalty parameter controlling the trade-off between the margin size and misclassification tolerance, and $\phi(\cdot)$ denotes the nonlinear mapping induced by the \textbf{RBF Kernel:}
\[
K(\mathbf{x}_i, \mathbf{x}_j) = \exp(-\gamma \|\mathbf{x}_i - \mathbf{x}_j\|^2)
\]
The model was optimized using the \texttt{libsvm} implementation, which employs a coordinate descent solver with kernel caching for efficiency.

With SVM-RBF, we evaluate it's accuracy by using cross-validation, and we was only able to achieve 87\% of accuracy.

% ============================================================

\section{Evaluation}

In turns of method evalution, we first split the dataset into training and validaion. 
Training dataset with 80\% of the data, while validation dataset with 20\% of the data.
\subsection{Evaluation Method}
In our evaluation stage, we use stratified K-fold cross-validation. The reason for this choice is that our dataset contains only 918 patient records, and using a fixed train/validation/test split may lead to overfitting due to the small number of data points.

\subsection{Metrics}

Same as progress report, we have in total six metrics to evaluate our model performance. The metrics used in this project include \textbf{accuracy, recall, precision, F1-score, and AUC–ROC and Confusion Matrix}. Our rationale for choosing these metrics is as follows.
First, in disease prediction, precision (closely related to Type II error) is especially important. Hospitals cannot afford to misclassify a patient with the disease as healthy. Therefore, minimizing false negatives is crucial.
In addition, we use the AUC–ROC curve because it is an effective way to evaluate the overall performance of a binary classifier.

We decided to keep using the metrics reported in our progress report, as these six metrics provide a sufficient and well-rounded understanding of our model’s performance for this task.
% ============================================================

\section{Process}

In our project proposal we planned to follow the Chi-square + PCA + RBF--SVM
framework from Gárate-Escamila et al.~\cite{GARATEESCAMILA2020100330}. In the
early stage of the project (before the progress report), we implemented a first
version of this pipeline: nominal features such as \texttt{ChestPainType},
\texttt{RestingECG}, and \texttt{ST\_Slope} were encoded as integers
(e.g., ATA~$\rightarrow 0$, NAP~$\rightarrow 1$, ASY~$\rightarrow 2$), and we
evaluated an RBF--SVM using a simple 80\%/20\% train--test split. This gave us
an initial accuracy of about 85\%, which confirmed that the approach was
reasonable but left room for improvement.

In the progress report, the TA gave us two concrete suggestions: (1) replace label
encoding of multi-class categorical variables with one-hot encoding, and (2)
experiment with a different models like a neural network. 
After that feedback we revised our preprocessing: we switched to
one-hot encoding (either via \texttt{pandas.get\_dummies} or 
\texttt{OneHotEncoder} in a \texttt{ColumnTransformer}), which expanded the
feature space to 18 columns and removed the artificial ordering implied by the
integer codes. 

Our original plan to strictly reproduce a full Chi-square + PCA pipeline
changed slightly as we test more with the Kaggle dataset. Because this
dataset has only 11 original features and relatively clean structure, we found
that PCA alone already captures most of the variance, and chi-square filtering
did not noticeably increase performance. So, we simplified the feature
engineering stage to focus on PCA and foces our comparison on three
models: Neural Network (as a simple baseline), RBF--SVM (our main model),
and LightGBM + SHAP (The method found online). Overall, we followed the spirit of
our original plan (PCA + SVM with additional baselines), but refined the
details of preprocessing and evaluation in response to TA feedback and empirical
results.

\section{Evaluation Strategy and Results (Error Anaysis) and Baseline}



% =========================================================
\subsection{Results}
The figures are listed in the last page, please check them out

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{kfoldvalidation.png}
\caption{5-fold precision scores.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{metrics_output.png}
\caption{Summary metrics across folds.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{AUC.png}
\caption{AUC–ROC curves.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{confuse_matrix.png}
\caption{Confusion matrices.}
\end{figure}


% ============================================================
\section*{Team Contributions}
Jeffrey Lin:  \\
ZiDi Yao:\\
Ke Ma: \\

% ============================================================
% Bibliography
\bibliographystyle{plain}
\bibliography{custom}

\end{document}
