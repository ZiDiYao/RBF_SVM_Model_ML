\documentclass[11pt]{article}

% Page layout (single-column, professional margins)
\usepackage[margin=1in]{geometry}

% Fonts and text
\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}

% Figures and tables
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}

% Math
\usepackage{amsmath}

% URLs
\usepackage{url}
\usepackage{float}

% Title
\title{Group 3 Final Report:\\Heart Disease Prediction using Machine Learning}

\author{
ZhiChong Lin, ZiDi Yao, Ke Ma\\
\texttt{yaoz25@mcmaster.ca, mak11@mcmaster.ca, lin281@mcmaster.ca}
}

\date{}
\setlength{\parindent}{2em} 

\begin{document}
\maketitle

% ============================================================
\section{Introduction}

    This project aims to use ML method to predict the likelihood
of heart disease based on eleven clinical and demographic features. Heart
disease continues to be a major global health concern, and early detection is
crucial for reducing severe outcomes. As outlined in our project proposal, the
goal of this work is to develop a reliable classification model that can
identify high-risk patients using routinely collected medical measurements.

    In this progress report, we will discuss the steps completed so far, including
dataset preprocessing, feature encoding, and the development of a Chi-Square +
PCA feature-engineering pipeline. We also present initial results from models
such as SVM, Logistic Regression, and Random Forest, and outline feedback from
the TA along with our planned next steps.

Building on these prior studies, our project adopts a supervised learning pipeline that combines Chi-square feature selection and Principal Component Analysis (PCA) with an RBF-kernel SVM classifier. 
We first apply a column transformer with median imputation and standardization for numerical features, and most-frequent imputation with one-hot encoding for categorical features;
Then we use a MinMaxScaler followed by \texttt{SelectKBest} with the Chi-square statistic to keep the top-$k$ informative features, 
and apply PCA with the number of components chosen using the Kaiser criterion~\cite{GARATEESCAMILA2020100330,kaiser1960factor}. 
The low-dimensional representation is fed into an RBF-SVM, and the full pipeline is evaluated on the Kaggle Heart Failure Prediction dataset~\cite{heartfailure_kaggle} 
using stratified $k$-fold cross validation, reporting accuracy, precision, recall, F1-score, and AUC as in previous work.


% ============================================================
\section{Related Work}

Our progress in this project builds directly on the foundation built in
Milestone01, where we considered both the clinical motivation and the technical
approaches. In that proposal, we discussed the limitations of traditional diagnostic methods and highlighted the
importance of ML models that can identify  multi-feature interactions such as age, cholesterol level, chest pain type, and 
ECG-related measurements, which observations align with prior work showing that 
heart disease prediction is well suited to ML due to its 
multivariate and non-linear nature.

As we talked about in M1, several existing studies have explored this predictive task using classical and
modern machine learning techniques. Logistic regression remains a common 
baseline method, as demonstrated by Awan \cite{musmanaslamawan_heartdisease_logistic},
who achieved approximately 85\% accuracy on the Kaggle using minimal
feature engineering. More advanced pipelines integrate supervised feature 
selection and dimensionality reduction. The Chi-Square + PCA framework proposed 
by Gárate-Escamila et al. \cite{GARATEESCAMILA2020100330} achieved up to 99\%
accuracy on multiple UCI heart disease datasets, motivating our decision in
Milestone~1 to incorporate both Chi-Square filtering and PCA into our own
preprocessing pipeline.

Moreover, foundational statistic work such as Kaiser factor analysis criterion
\cite{kaiser1960factor} provides justification for retaining only
principal components with eigenvalues greater than one, a rule we apply in our
dimensionality reduction stage. Other work has examined optimization strategies 
for medical classification models, including scalable L1-regularized training
\cite{andrew2007scalable} and multi-task predictive structure learning
\cite{Ando2005}, which highlight broader approaches to improving generalization
when datasets are small—one of the challenges noted in our proposal.

\section{Dataset and Preprocessing} 

This section will introduce the raw dataset we used, and how we clean and process it. 

\subsection{Dataset Description}

The dataset we used in this project is the \textit{Heart Failure Prediction Dataset}
published by Fedesoriano on Kaggle~\cite{heartfailure_kaggle}.  
It contains \textbf{918 patient observations} and \textbf{12 attributes}, including 
11 clinical predictor variables and one binary target label indicating the presence 
of heart disease. This dataset was designed to support research on early detection 
of cardiovascular risks, particularly heart failure, which remains one of the leading 
causes of global mortality.

The dataset includes a mixture of demographic features ( Age, Sex), 
physiological measurements (like RestingBP, Cholesterol, MaxHR), and exercise-induced 
ECG-related metrics (ExerciseAngina, Oldpeak, ST\_Slope). Those attributes show 
common risk factors used in medical diagnostics for cardiovascular disease and have 
been widely adopted in machine learning models for clinical prediction tasks.

A complete list of raw features and their corresponding descriptions is provided in 
Table~\ref{tab:rawfeatures}.


\begin{table}[htbp]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Feature} & \textbf{Description} \\
\midrule
Age & Age of patient (years) \\
Sex & Biological sex (M/F) \\
ChestPainType & Chest pain type (ATA, NAP, ASY, TA) \\
RestingBP & Resting blood pressure (mm Hg) \\
Cholesterol & Serum cholesterol (mg/dL) \\
FastingBS & Fasting blood sugar (0/1) \\
RestingECG & Resting ECG results (Normal, ST, LVH) \\
MaxHR & Maximum heart rate achieved \\
ExerciseAngina & Exercise-induced angina (Y/N) \\
Oldpeak & ST depression value induced by exercise \\
ST\_Slope & Slope of ST segment (Up, Flat, Down) \\
HeartDisease & Target label (1 = disease, 0 = healthy) \\
\bottomrule
\end{tabular}
\caption{Raw dataset features.}
\label{tab:rawfeatures}
\end{table}

Originally, the dataset contains:
\[
\textbf{918 samples} \quad \times \quad \textbf{11 features}.
\]
\subsection{Feature Preprocessing}

The feature matrix \(X\) was constructed by removing the target column and
retaining the remaining 18 input attributes.
Since the dataset includes both numerical and categorical variables, several
preprocessing steps were required to convert all values into a machine-learning‐
ready numeric form.

\paragraph{Binary Encoding}

Three features, namely Sex, ExerciseAngina, and FastingBS contain only two possible values and were mapped directly to
0/1 following our preprocessing script:

\begin{itemize}
    \item \textbf{Sex:} \texttt{M} $\rightarrow$ 1,\; \texttt{F} $\rightarrow$ 0
    \item \textbf{ExerciseAngina:} \texttt{Y} $\rightarrow$ 1,\; \texttt{N} $\rightarrow$ 0
    \item \textbf{FastingBS:} preserved as integer \texttt{0/1}
\end{itemize}

\paragraph{Ordinal Mapping of Multi-Class Features}

Three categorical features contain more than two categories.
In the stored processed dataset (\texttt{X\_encoded.csv}), they were converted
to integer codes according to predefined mappings:

\[
\text{ChestPainType: } \{\texttt{ATA}, \texttt{NAP}, \texttt{ASY}, \texttt{TA}\}
\rightarrow \{0,1,2,3\},
\]

\[
\text{RestingECG: } \{\texttt{Normal}, \texttt{ST}, \texttt{LVH}\}
\rightarrow \{0,1,2\},
\]

\[
\text{ST\_Slope: } \{\texttt{Up}, \texttt{Flat}, \texttt{Down}\}
\rightarrow \{0,1,2\}.
\]

These mappings avoid string-based ambiguity and ensure that all feature columns are numeric at the preprocessing stage.

In contrast from progress report, we adopted feedback from TA to change our way of presenting One-Hot Encoding, instead of present them in one single column to split them across the columns 
for every single category.

Therefore, after spliting them into one-hot encoding, the final dataset shape changes to 918 x 18.

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Feature} & \textbf{Description} \\
\midrule
Age & Age of patient (years) \\
Sex & Biological sex (M/F) \\
ChestPainType\_0 & ATA \\
ChestPainType\_1 & NAP \\
ChestPainType\_2 & ASY \\
ChestPainType\_3 & TA \\
RestingBP & Resting blood pressure (mm Hg) \\
Cholesterol & Serum cholesterol (mg/dL) \\
FastingBS & Fasting blood sugar (0/1) \\
RestingECG\_0 & Normal \\
RestingECG\_1 & ST \\
RestingECG\_2 & LVH \\
MaxHR & Maximum heart rate achieved \\
ExerciseAngina & Exercise-induced angina (Y/N) \\
Oldpeak & ST depression value induced by exercise \\
ST\_Slope\_0 & Up \\
ST\_Slope\_1 & Flat \\
ST\_Slope\_2 & Down \\
HeartDisease & Target label (1 = disease, 0 = healthy) \\
\bottomrule
\end{tabular}
\caption{One-Hot Encoding Table.}
\label{tab:rawfeatures}
\end{table}


\subsection{Target Label Extraction}

The target label \texttt{HeartDisease} is a binary indicator representing whether
a patient shows signs of heart disease.  
We extract this column and converted it to integer form using:
\[
y = \texttt{df['HeartDisease'].astype(int)}.
\]
The resulting is a one-dimensional vector , which was saved as \texttt{processed/y.csv}
for all downstream training and evaluation.

The cleaned dataset was saved to \texttt{processed/X\_encoded.csv}, and
the corresponding feature names were exported to
\texttt{processed/feature\_names.txt} for reproducibility.


% ============================================================

% This section corresponds to Item 3 in the project instructions.
\section{Model Inputs (Features)}

During our data preprocessing phase, we utilize \texttt{scikit-learn} built-in function \texttt{pipeline} to transform our data before feeding into Machine Learning Model
\vspace{1em}
The dataset has both numerical and categorical features, in the previous part we mentioned that for each numerical part we standardized them, 
while for categorical part we used one-hot encoding to transform them into vectors.
\vspace{1em}
In result, we have total 18 features after preprocessing, including 8 numerical features and 10 categorical features ``(One-Hot Encoding)''.
\vspace{1em}
Something different from progress report, as we realize our dataset is way too easy compare to the heart diease dataset from the paper. So, this time we decided
to only use PCA method as our feature engineering method, instead of using Chi-square + PCA method \cite{GARATEESCAMILA2020100330}.
\vspace{1em}

\begin{itemize}
    \item \textbf{PCA:}  
    After feature selection, we then applied Principal Component Analysis (PCA) to reduce the dimensionality of the selected features. PCA works by identifying the directions (principal components) in which the data varies the most, and projecting the data onto these directions.

    To determine the number of principal components to retain, we adopt the \textbf{Kaiser criterion} \cite{kaiser1960factor}. 
    This rule suggests keeping only components with eigenvalues greater than 1.0.

    After doing a experiments of calculating eigenvalues for every single increase of principal components, we found that the first five components have eigenvalues greater than 1.0. Thus, we decided to retain five principal components for our final feature representation.   
\end{itemize}

Hence, each patient sample is represented as a compact (data, 5) feature vector summarizing the most informative physiological and categorical characteristics. 
This final feature set is then used as input to our machine learning model.

% ============================================================
% \section{Model Implementation}
% Describe the machine learning model(s) used.

% Examples:
% \begin{itemize}
%     \item RBF-kernel Support Vector Machine (SVM)
%     \item Justification for using SVM
%     \item Hyperparameters used (C, gamma)
%     \item Training pipeline and libraries (scikit-learn)
% \end{itemize}

% This section corresponds to Item 4 of the project instructions.

\section{Model Implementation}

We have implemented a supervised learning pipeline for binary classification of heart disease presence. 
Our main model is a \textbf{Support Vector Machine (SVM)} with a \textbf{Radial Basis Function (RBF)} kernel, implemented using the \texttt{scikit-learn} library. 
This kernel choice allows the decision boundary to be nonlinear, which is important given the heterogeneous mixture of categorical and numerical medical features in the dataset. 

\textbf{Loss Function:}
\[
\min_{\mathbf{w},b} \frac{1}{2}\|\mathbf{w}\|^2 + C \sum_{i=1}^n \max(0, 1 - y_i(\mathbf{w}^\top \phi(\mathbf{x}_i) + b))
\]
where $C$ is the penalty parameter controlling the trade-off between the margin size and misclassification tolerance, and $\phi(\cdot)$ denotes the nonlinear mapping induced by the \textbf{RBF Kernel:}
\[
K(\mathbf{x}_i, \mathbf{x}_j) = \exp(-\gamma \|\mathbf{x}_i - \mathbf{x}_j\|^2)
\]
The model was optimized using the \texttt{libsvm} implementation, which employs a coordinate descent solver with kernel caching for efficiency.

To evaluate our implementation, we compared SVM–RBF against two baseline models: 
\begin{itemize}
    \item \textbf{Logistic Regression:} This baseline model was chosen from kaggle \cite{musmanaslamawan_heartdisease_logistic}, where the author didn't use features selection or dimensionality reduction, and he was able to achieve 85\% accuracy.
    \item \textbf{Random Forest:} From this paper \cite{GARATEESCAMILA2020100330}, the author has 98\% accuracy by using Random Forest with Chi-PCA method. However, he used a 74 features and around 1000 datapoint of heartdiease dataset from UCL.
\end{itemize}

With SVM-RBF, we evaluate it's accuracy by using cross-validation, and we was only able to achieve 86\% of accuracy.

We then use Random Forest and Logistic Regression as our model, Randomforest was able to achieve 87\% accuracy, while Logistic Regression was able to achieve 85\% accuracy.

Varies reason can be introduces in here, such as different dataset, the quality of dataset, or minor changes in the preprocessing phase that effect the data values meaning.

In future iterations, we plan to explore a \textbf{neural network architecture} (e.g., a multi-layer perceptron) to capture more complex feature interactions and potentially improve generalization performance. 
We also intent to change the detail in our preprocessing phase, such as using different order, or different preprocessing tools to present the data in a better way.

% ============================================================
\section{Evaluation Strategy and Results}

In turns of method evalution, we first split the dataset into training and validaion. 
Training dataset with 80\% of the data, while validation dataset with 20\% of the data.
\subsection{Evaluation Method}
In our evaluation stage, we use stratified K-fold cross-validation. The reason for this choice is that our dataset contains only 918 patient records, and using a fixed train/validation/test split may lead to overfitting due to the small number of data points.

\subsection{Metrics}
\[
\textbf{SVM with RBF Kernel Model Performance}:
\]
Same as progress report, we have in total six metrics to evaluate our model performance. The metrics used in this project include \textbf{accuracy, recall, precision, F1-score, and AUC–ROC and Confusion Matrix}. Our rationale for choosing these metrics is as follows.
First, in disease prediction, precision (closely related to Type II error) is especially important. Hospitals cannot afford to misclassify a patient with the disease as healthy. Therefore, minimizing false negatives is crucial.
In addition, we use the AUC–ROC curve because it is an effective way to evaluate the overall performance of a binary classifier.

\subsection{Results}
The figures are listed in the last page, please check them out

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{kfoldvalidation.png}
\caption{5-fold precision scores.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{metrics_output.png}
\caption{Summary metrics across folds.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{AUC.png}
\caption{AUC–ROC curves.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{confuse_matrix.png}
\caption{Confusion matrices.}
\end{figure}


% ============================================================
\section*{Team Contributions}
Jeffrey Lin: Section 4 to 5 and implementation of model  \\
ZiDi Yao: Section 1 to 3 and raw data introduction and processing\\
Ke Ma: Section 6 to 7 and data validation and clean\\

% ============================================================
% Bibliography
\bibliographystyle{plain}
\bibliography{custom}

\end{document}
